{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real word V2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows diversity of V2V usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"device=gpu4\"\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=\"device=gpu4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from librosa import load, logamplitude\n",
    "from librosa.feature import melspectrogram\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../clear\")\n",
    "from CoolSoundNetwork import Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv(\"../../data/pronuns.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = Network(load_weights=False, vec_weights_file_name='../../data/weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../data/images/\"\n",
    "output_path = \"../../data/vectors/\"\n",
    "for im in tqdm(os.listdir(\"../../data/images/\")):\n",
    "    img = Image.open(data_path+im)\n",
    "    vectors = network.vectorizer(voice_array=np.array(img))\n",
    "    for index, vector in enumerate(vectors):\n",
    "        np.save(output_path+im.strip(\".png\")+\"_\"+str(index), vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out small classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category = \"accent\"\n",
    "final_categorys = []\n",
    "\n",
    "min_num = 100\n",
    "\n",
    "for cl, num_of_inst in enumerate(df[category].value_counts()):\n",
    "    if num_of_inst >= min_num:\n",
    "        final_categorys.append(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df[category].isin(final_categorys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accent_count = len(df.accent.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "recordings = pd.Series(index=df.pronun_id.unique())\n",
    "for file in tqdm(os.listdir(\"../../data/vectors/\")):\n",
    "    name = file.split(\"_\")[0]\n",
    "    try:\n",
    "        recordings[name]\n",
    "    except:\n",
    "        os.remove(\"../../data/vectors/\"+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 1000\n",
    "\n",
    "temp_df = df.set_index(\"pronun_id\")\n",
    "\n",
    "directory = os.listdir(\"../../data/vectors/\")\n",
    "\n",
    "men_counter = 0\n",
    "women_counter = 0\n",
    "\n",
    "accent_counter = np.zeros(accent_count)\n",
    "\n",
    "for file in directory:\n",
    "    if men_counter >= test_size and women_counter >= test_size:\n",
    "        break\n",
    "    if df.loc[file.split(\"_\")[0]].gender and men_counter < test_size:\n",
    "        shutil.move(\"../../data/vectors/\"+file, \"../../data/vectors/test/\"+file)\n",
    "        men_counter += 1\n",
    "    elif women_counter < test_size:\n",
    "        shutil.move(\"../../data/vectors/\"+file, \"../../data/vectors/test/\"+file)\n",
    "        women_counter += 1\n",
    "\n",
    "del temp_df\n",
    "\n",
    "test_df = df[df.pronun_id.isin(list(map(lambda x: x.split(\"_\")[0], os.listdir(\"../../data/vectors/test/\"))))]\n",
    "test_df = test_df.set_index(\"pronun_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = []\n",
    "test_Y = [test.gender, test.accent]\n",
    "\n",
    "dir_names = list(map(lambda x: x.strip(\".npy\"), directory))\n",
    "\n",
    "for rec_id in test_df.keys:\n",
    "    recordings = [x for x in dir_names if x.split(\"_\")[0] == rec_id]\n",
    "    if len(recordings) > 1:\n",
    "        rec_name = np.random.choice(recordings)\n",
    "    else:\n",
    "        rec_name = recordings[0]\n",
    "    rec_name += \".npy\"\n",
    "    \n",
    "    test_X.append(np.load(\"../../data/vectors/test/\"+rec_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.sandbox.cuda): ERROR: Not using GPU. Initialisation of device 4 failed:\n",
      "initCnmem: cnmemInit call failed! Reason=CNMEM_STATUS_OUT_OF_MEMORY. numdev=1\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is enabled with initial size: 45.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_tensor = T.matrix(\"Vector input\")\n",
    "target_gender = T.ivector(\"Target gender\")\n",
    "target_accent = T.ivector(\"Target acent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_ = lasagne.layers.InputLayer((100, 100), input_var=input_tensor, name=\"Network input\")\n",
    "batch_norm0 = lasagne.layers.batch_norm(input_, name=\"Batch normalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GenderNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gend_dense0 = lasagne.layers.DenseLayer(batch_norm0, 50, name=\"Dense 0\")\n",
    "gend_dense1 = lasagne.layers.DenseLayer(gend_dense0, 20, name=\"Dense 1\")\n",
    "gender_out = lasagne.layers.DenseLayer(gend_dense1, 1, nonlinearity=lasagne.nonlinearities.sigmoid, name=\"Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_out.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_predicted = lasagne.layers.get_output(gender_out)\n",
    "gender_param = lasagne.layers.get_all_params(gender_out, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_loss = lasagne.objectives.binary_crossentropy(gender_predicted, target_gender).mean()\n",
    "\n",
    "gender_updates = lasagne.updates.adagrad(gender_loss, gender_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AccentNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accent_dense0 = lasagne.layers.DenseLayer(batch_norm0, 200, name=\"Dense 0\")\n",
    "accent_dense1 = lasagne.layers.DenseLayer(accent_dense0, 100, name=\"Dense 1\")\n",
    "accent_out = lasagne.layers.DenseLayer(accent_dense1, accent_count,\n",
    "                                       nonlinearity=lasagne.nonlinearities.softmax, name=\"Accent output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 111)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accent_out.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accent_predicted = lasagne.layers.get_output(accent_out)\n",
    "accent_param = lasagne.layers.get_all_params(accent_out, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accent_loss = lasagne.objectives.binary_crossentropy(accent_predicted, target_accent).mean()\n",
    "\n",
    "accent_updates = lasagne.updates.adagrad(accent_loss, accent_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_train = theano.function([input_.input_var, target_gender], updates=gender_updates)\n",
    "accent_train = theano.function([input_.input_var, target_accent], updates=accent_updates)\n",
    "\n",
    "gender_predict = theano.function([input_.input_var], gender_predicted)\n",
    "accent_predict = theano.function([input_.input_var], accent_predicted)\n",
    "\n",
    "predict = theano.function([input_.input_var], [gender_predicted, accent_predicted])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(input_path, output_df, batchsize, index_col=\"pronun_id\",\n",
    "                            target_names=[\"gender\"],shuffle=True):\n",
    "    input_files = np.array(list(map(lambda x: input_path+x, os.listdir(input_path))))\n",
    "    input_files = np.array(list(filter(lambda x: os.isfile(x), input_files)))\n",
    "    output_df = output_df.set_index(index_col)\n",
    "    targets = output_df[target_names]\n",
    "    del output_df\n",
    "    \n",
    "    if shuffle:\n",
    "        indices = np.arange(input_files.size)\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(input_files) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        inputs = []\n",
    "        rec_targ = []\n",
    "        for inp in input_files[excerpt]:\n",
    "            naming = inp.split(\"_\")[0].split(\"/\")\n",
    "            name = naming[len(naming)-1]\n",
    "            inputs.append(np.load(inp))\n",
    "            rec_targ.append(targets[name])\n",
    "        yield np.array(inputs), np.array(rec_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "13350\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-36d6e5f1b0ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/vectors/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mgender_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcurr\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-146-d78d2473fef8>\u001b[0m in \u001b[0;36miterate_minibatches\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mnaming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaming\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mrec_targ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_targ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0m_ZIP_PREFIX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PK\\x03\\x04'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIC_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# back-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ZIP_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH = 5\n",
    "size = df.pronun_id.size\n",
    "\n",
    "gender_pred, accent_pred = predict(test_X)\n",
    "g_l =  gender_loss(gender_pred, test_Y[0])\n",
    "a_l = acccent_loss(accent_pred, test_Y[1])\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    curr = 0\n",
    "    for x, y in iterate_minibatches(\"../../data/vectors/\", df, 150, target_names=[\"gender\", \"accent\"]):\n",
    "        gender_train(x, y[0])\n",
    "        accent_train(x, y[1])\n",
    "        curr+= 150\n",
    "        clear_output()\n",
    "        print(\"Epoch: \", epoch)\n",
    "        if curr % 100 == 0:\n",
    "            gender_pred, accent_pred = predict(test_X)\n",
    "            g_l =  gender_loss(gender_pred, test_Y[0])\n",
    "            a_l = acccent_loss(accent_pred, test_Y[1])\n",
    "        print(\"Gender accuracy: \", g_l)\n",
    "        print(\"Accent accuracy: \", a_l)\n",
    "        print(curr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"accent_weights\", accent_param())\n",
    "np.save(\"gender_weights\", gender_param())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_Y = predict(input_X)\n",
    "print(\"Gender accuracy: \", gender_loss(predicted_Y, test_Y[0]))\n",
    "print(\"Accent accuracy: \", accent_loss(predicted_Y, test_Y[1]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "706329e9d2724b3d8c784215b6ad7787": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
