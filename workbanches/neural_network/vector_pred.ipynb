{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real word V2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows diversity of V2V usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"device=gpu4\"\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=\"device=gpu4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from librosa import load, logamplitude\n",
    "from librosa.feature import melspectrogram\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../clear\")\n",
    "from CoolSoundNetwork import Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv(\"../../data/pronuns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "encoded = enc.fit_transform(df.accent)\n",
    "df[\"coded\"] = encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = Network(vectorizer_weights_file_name='../../data/vectorizer_weights.npy', load_similar_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "women_test = list(df[df.gender == False].pronun_id)[:500]\n",
    "men_test = list(df[df.gender == True].pronun_id)[:500]\n",
    "\n",
    "data_path = \"../../data/images/\"\n",
    "output_path = \"../../data/vectors/\"\n",
    "\n",
    "test = women_test + men_test\n",
    "np.random.shuffle(np.array(test))\n",
    "train = df[~df.pronun_id.isin(test)]\n",
    "\n",
    "for t in test:\n",
    "    img = Image.open(data_path+t+\".png\")\n",
    "    vectors = network.vectorizer(voice_array=np.array(img))\n",
    "    for index, vector in enumerate(vectors):\n",
    "        np.save(output_path+\"test/\"+t+\"_\"+str(index), vector)\n",
    "\n",
    "for tr in train.pronun_id:\n",
    "    img = Image.open(data_path+t+\".png\")\n",
    "    vectors = network.vectorizer(voice_array=np.array(img))\n",
    "    for index, vector in enumerate(vectors):\n",
    "        np.save(output_path+tr+\"_\"+str(index), vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "for f in os.listdir(\"../../data/vectors\"):\n",
    "    train.append(f.split(\"_\")[0])\n",
    "\n",
    "for f in os.listdir(\"../../data/vectors/test\"):\n",
    "    test.append(f.split(\"_\")[0])\n",
    "train = np.unique(train)\n",
    "test = np.unique(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = df[df.pronun_id.isin(train)]\n",
    "test_df = df[df.pronun_id.isin(test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.set_index(\"pronun_id\")\n",
    "test_df = test_df.set_index(\"pronun_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out small classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category = \"accent\"\n",
    "final_categorys = []\n",
    "\n",
    "min_num = 100\n",
    "\n",
    "for cl, num_of_inst in enumerate(df[category].value_counts()):\n",
    "    if num_of_inst >= min_num:\n",
    "        final_categorys.append(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df[category].isin(final_categorys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accent_count = len(df.accent.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "recordings = pd.Series(index=df.pronun_id.unique())\n",
    "for file in tqdm(os.listdir(\"../../data/vectors/test\")):\n",
    "    name = file.split(\"_\")[0]\n",
    "    if name == \"test\":\n",
    "        continue\n",
    "    try:\n",
    "        recordings[name]\n",
    "    except:\n",
    "        os.remove(\"../../data/vectors/test/\"+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_size = 1000\n",
    "\n",
    "temp_df = df.set_index(\"pronun_id\")\n",
    "\n",
    "directory = os.listdir(\"../../data/vectors/\")\n",
    "\n",
    "men_counter = 0\n",
    "women_counter = 0\n",
    "\n",
    "for file in directory:\n",
    "    if men_counter >= test_size and women_counter >= test_size:\n",
    "        break\n",
    "    if temp_df.loc[file.split(\"_\")[0]].gender and men_counter < test_size:\n",
    "        shutil.move(\"../../data/vectors/\"+file, \"../../data/vectors/test/\"+file)\n",
    "        men_counter += 1\n",
    "    elif women_counter < test_size:\n",
    "        shutil.move(\"../../data/vectors/\"+file, \"../../data/vectors/test/\"+file)\n",
    "        women_counter += 1\n",
    "\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = df[df.pronun_id.isin(test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = df[df.pronun_id.isin(list(map(lambda x: x.split(\"_\")[0], os.listdir(\"../../data/vectors/test/\"))))]\n",
    "test_df = test_df.set_index(\"pronun_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = df[~df.pronun_id.isin(test_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "women = t[t.gender == False].pronun_id\n",
    "import shutil\n",
    "counter = 0\n",
    "dire = os.listdir(\"../../data/vectors/\")\n",
    "for f in dire:\n",
    "    if f.split(\"_\")[0] in women.values:\n",
    "        shutil.move(\"../../data/vectors/\"+f, \"../../data/vectors/test/\"+f)\n",
    "        counter += 1\n",
    "        if counter == 200:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "test_X = []\n",
    "test_Y = np.array(test_df.gender)\n",
    "\n",
    "for index in test_df.index:\n",
    "    files = glob.glob(\"../../data/vectors/test/\"+index+\"*\")\n",
    "    test_X.append(np.load(files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "test_X = []\n",
    "test_Y = []\n",
    "\n",
    "for f in os.listdir(\"../../data/vectors/test\"):\n",
    "    name = f.split(\"_\")[0]\n",
    "    test_X.append(np.load(\"../../data/vectors/test/\"+f))\n",
    "    test_Y.append(test_df.loc[name].gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_tensor = T.matrix(\"Vector input\")\n",
    "target_gender = T.ivector(\"Target gender\")\n",
    "target_accent = T.ivector(\"Target acent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_ = lasagne.layers.InputLayer((None, 300), input_var=input_tensor, name=\"Network input\")\n",
    "batch_norm0 = lasagne.layers.batch_norm(input_, name=\"Batch normalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GenderNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gend_dense0 = lasagne.layers.DenseLayer(batch_norm0, 50, name=\"Dense 0\")\n",
    "gend_dense1 = lasagne.layers.DenseLayer(gend_dense0, 20, name=\"Dense 1\")\n",
    "gender_out = lasagne.layers.DenseLayer(gend_dense1, 1, nonlinearity=lasagne.nonlinearities.sigmoid, name=\"Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_out.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_predicted = lasagne.layers.get_output(gender_out)\n",
    "gender_param = lasagne.layers.get_all_params(gender_out, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_loss = lasagne.objectives.binary_crossentropy(gender_predicted, target_gender).mean()\n",
    "\n",
    "gender_updates = lasagne.updates.adagrad(gender_loss, gender_param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AccentNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accent_dense0 = lasagne.layers.DenseLayer(batch_norm0, 200, name=\"Dense 0\")\n",
    "accent_dense1 = lasagne.layers.DenseLayer(accent_dense0, 100, name=\"Dense 1\")\n",
    "accent_out = lasagne.layers.DenseLayer(accent_dense1, accent_count,\n",
    "                                       nonlinearity=lasagne.nonlinearities.softmax, name=\"Accent output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 111)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accent_out.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accent_predicted = lasagne.layers.get_output(accent_out)\n",
    "accent_param = lasagne.layers.get_all_params(accent_out, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accent_loss = lasagne.objectives.binary_crossentropy(accent_predicted, target_accent).mean()\n",
    "\n",
    "accent_updates = lasagne.updates.adagrad(accent_loss, accent_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_train = theano.function([input_.input_var, target_gender], updates=gender_updates)\n",
    "accent_train = theano.function([input_.input_var, target_accent], updates=accent_updates)\n",
    "\n",
    "gender_predict = theano.function([input_.input_var], gender_predicted)\n",
    "accent_predict = theano.function([input_.input_var], accent_predicted)\n",
    "\n",
    "predict = theano.function([input_.input_var], [gender_predicted, accent_predicted])\n",
    "\n",
    "print_gender_param = theano.function([], gender_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(input_path, output_df, batchsize, index_col=\"pronun_id\",\n",
    "                            target_names=[\"gender\"],shuffle=True):\n",
    "    input_files = np.array(list(map(lambda x: input_path+x, os.listdir(input_path))))\n",
    "    input_files = np.array(list(filter(lambda x: os.path.isfile(x), input_files)))\n",
    "    #output_df = output_df.set_index(index_col)\n",
    "    targets = output_df[target_names]\n",
    "    del output_df\n",
    "    if shuffle:\n",
    "        indices = np.arange(input_files.size)\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(input_files) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        inputs = []\n",
    "        rec_targ = []\n",
    "        for inp in input_files[excerpt]:\n",
    "            naming = inp.split(\"_\")[0].split(\"/\")\n",
    "            name = naming[len(naming)-1]\n",
    "            inputs.append(np.load(inp))\n",
    "            rec_targ.append(targets.loc[name])\n",
    "        yield np.array(inputs), np.array(rec_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Gender accuracy:  0.499554909297\n",
      "142800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-83326111c179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/vectors/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mgender_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcurr\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-a34fc187f070>\u001b[0m in \u001b[0;36miterate_minibatches\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mnaming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaming\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mrec_targ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_targ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0m_ZIP_PREFIX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PK\\x03\\x04'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIC_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# back-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ZIP_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH = 5\n",
    "size = df.pronun_id.size\n",
    "\n",
    "gender_pred, accent_pred = predict(test_X)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    curr = 0\n",
    "    for x, y in iterate_minibatches(\"../../data/vectors/\", train_df, 150, target_names=[\"gender\"]):\n",
    "        gender_train(x, list(map(lambda x:x[0], y)))\n",
    "        curr+= 150\n",
    "        clear_output()\n",
    "        print(\"Epoch: \", epoch)\n",
    "        if curr % 100 == 0:\n",
    "            gender_pred, accent_pred = predict(test_X)\n",
    "        print(\"Gender accuracy: \", roc_auc_score(test_Y, gender_pred))\n",
    "        print(curr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.56398916],\n",
       "       [ 0.17789808],\n",
       "       [ 0.66043985],\n",
       "       [ 0.0262416 ],\n",
       "       [ 0.26344365],\n",
       "       [ 0.61810315],\n",
       "       [ 0.62714779],\n",
       "       [ 0.66823637],\n",
       "       [ 0.41940391],\n",
       "       [ 0.27778909],\n",
       "       [ 0.19782983],\n",
       "       [ 0.69163442],\n",
       "       [ 0.27159095],\n",
       "       [ 0.41585603],\n",
       "       [ 0.68751299],\n",
       "       [ 0.32484204],\n",
       "       [ 0.09851819],\n",
       "       [ 0.33192056],\n",
       "       [ 0.90256232],\n",
       "       [ 0.6444571 ]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gender_param()[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"accent_weights\", accent_param())\n",
    "np.save(\"gender_weights\", gender_param())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_Y = predict(input_X)\n",
    "print(\"Gender accuracy: \", gender_loss(predicted_Y, test_Y[0]))\n",
    "print(\"Accent accuracy: \", accent_loss(predicted_Y, test_Y[1]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "bca077de1bee48bdb36af353a4612241": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
