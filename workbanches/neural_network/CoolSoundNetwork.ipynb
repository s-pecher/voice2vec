{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"device=gpu4\"\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=\"device=gpu4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from librosa import load, logamplitude\n",
    "from librosa.feature import melspectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOUND_SHAPE = (500, 513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv(\"pronuns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(img_name):\n",
    "    return np.array(Image.open(\"../../data/images/{}.png\".format(img_name)))\n",
    "\n",
    "# def get_spectrogram(path):\n",
    "#     \"\"\"Строим спектограмму из wav файла\"\"\"\n",
    "#     y, sr = load(\"mongodb/sounds/%s.wav\" % path)\n",
    "#     S = melspectrogram(y, sr=sr, n_mels=100)\n",
    "#     log_S = logamplitude(S, ref_power=np.max)\n",
    "#     return log_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(get_spectrogram(\"585fda10698f828c848d862d\"))\n",
    "get_spectrogram(\"585fda10698f828c848d862d\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.min(get_spectrogram(\"585fda10698f828c848d862d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _id in tqdm(set([i[:-4] for i in os.listdir(\"mongodb/sounds\")])):\n",
    "    get_spectrogram(\"../../sounds/%s.wav\" % _id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_train = {}\n",
    "for user in tqdm(df.user.unique()):\n",
    "    user_sp = {}\n",
    "    user_sp_data = df[df.user == user].pronun_id.values\n",
    "    final_train[user] = user_sp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import bsr_matrix as sp_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def as_matrix(ar, shape):\n",
    "    ret_mat = np.zeros((len(ar), shape[0], shape[1]), dtype=\"float16\")\n",
    "    for i, vec in enumerate(ar):\n",
    "        try:\n",
    "            if vec.shape[0] > shape[0]:\n",
    "                ret_mat[i, :, :] = vec[:shape[0], :]/200.\n",
    "            else:\n",
    "                ret_mat[i, :vec.shape[0], :] = vec/200.\n",
    "        except IndexError:\n",
    "            print(vec.shape)\n",
    "            raise IndexError\n",
    "\n",
    "    return ret_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "from numpy.random import choice\n",
    "\n",
    "class VoicesData:\n",
    "    def __init__(self, path='users.dl'):\n",
    "        # Путь до dill моделf\n",
    "        self.path = path\n",
    "#         Defaultdict информации\n",
    "        self.base = dill.load(open(self.path, 'rb'))\n",
    "#         self.base = final_train\n",
    "    def __getitem__(self, item):\n",
    "        return self.base[item]\n",
    "    def save(self):\n",
    "        \"\"\"Поскольку это не стандартная DB, тут нужна функция сохранения\"\"\"\n",
    "        dill.dump(self.base, open(self.path, 'wb'))\n",
    "\n",
    "    def get_train_vec(self, shape=SOUND_SHAPE):\n",
    "        \"\"\"Делаем из данных train выборку\"\"\"\n",
    "        for key in tqdm(self.base.keys()): \n",
    "            train = []\n",
    "            if len(self.base[key]) >= 2:\n",
    "                for _ in range(0, len(self.base[key]), 2):\n",
    "                    values = choice(list(self.base[key]), 2)\n",
    "                    a = np.asarray(get_spectrogram(values[0]))\n",
    "                    b = np.asarray(get_spectrogram(values[1]))\n",
    "                    other = choice(list(self.base), 1)[0]\n",
    "                    c = np.asarray(get_spectrogram(choice(list(self.base[other]), 1)[0]))\n",
    "\n",
    "                    other_value = c\n",
    "                    value_first = a\n",
    "                    value_second = b\n",
    "#                     print(a.shape)\n",
    "                    # other_value.resize(shape) # value_first.resize(shape) # value_second.resize(shape)\n",
    "                    some = as_matrix((value_first, other_value, value_second), shape)\n",
    "                    train.append(some)\n",
    "#                     break\n",
    "                    \n",
    "#                 print(len(train))\n",
    "                yield train\n",
    "            else:\n",
    "#                 print(\"I'm empty\")\n",
    "                pass\n",
    "\n",
    "    def get_train_people(self, shape=SOUND_SHAPE, count=10000):\n",
    "        X = []\n",
    "        y = []\n",
    "        people = list(self.base.keys())\n",
    "        for _ in tqdm(range(0, count//2)):\n",
    "            man = choice(people, 1)\n",
    "            track = choice(list(self.base[man[0]]), 2)\n",
    "\n",
    "            a = get_spectrogram(track[0])\n",
    "            b = get_spectrogram(track[1])\n",
    "\n",
    "            X.extend([as_matrix([a, b], shape)])\n",
    "\n",
    "        y.extend([1 for _ in range(len(X))])\n",
    "        X_ol = len(X)\n",
    "#                 break\n",
    "\n",
    "        \n",
    "        for _ in tqdm(range(count//2, count)):\n",
    "            man1 = choice(people, 1)[0]\n",
    "            people_new = people[:]\n",
    "            people_new.remove(man1)\n",
    "\n",
    "            man2 = choice(people_new, 1)[0]\n",
    "            \n",
    "#             print(man1)\n",
    "            sou = self.base[man1]\n",
    "            a = choice(list(sou), 1)[0]\n",
    "            sou = self.base[man2]\n",
    "            b = choice(list(sou), 1)[0]\n",
    "            \n",
    "            X.append(as_matrix([get_spectrogram(a),\n",
    "                      get_spectrogram(b)], shape))\n",
    "        y.extend([0 for _ in range(len(X) - X_ol)])\n",
    "        return np.array(X, dtype=\"float16\"), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "choice([0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users = VoicesData(\"../../data/users.dl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = users.get_train_people(count=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = users.get_train_vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"X\", X)\n",
    "np.save(\"y\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 4: GeForce GTX 1080 (CNMeM is enabled with initial size: 45.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "from lasagne.layers import InputLayer, DenseLayer, ReshapeLayer, Conv1DLayer, MaxPool1DLayer, GlobalPoolLayer, \\\n",
    "    get_output, get_all_params, get_all_param_values, set_all_param_values\n",
    "\n",
    "from lasagne.nonlinearities import very_leaky_rectify, tanh\n",
    "\n",
    "from lasagne.updates import adagrad\n",
    "\n",
    "def make_speechtovec(incoming, sound_shape, num_units, **kwargs):\n",
    "    \"\"\"\n",
    "    :param incoming: the layer feeding into this layer, or the expected input shape.\n",
    "    :param sound_shape: shape of freq x time\n",
    "    :param num_units: output vector dimension\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    input_reshape = ReshapeLayer(incoming, (-1,) + sound_shape)  # Сворачиваем все записи друг за другом\n",
    "    convolution = Conv1DLayer(input_reshape, num_filters=100, filter_size=5,\n",
    "                              nonlinearity=very_leaky_rectify, name=\"Convolutional\")\n",
    "    pooling = MaxPool1DLayer(convolution, 2)\n",
    "    global_pooling = GlobalPoolLayer(pooling)\n",
    "    dense = DenseLayer(global_pooling, num_units=300, name=\"Dense\")\n",
    "    output_dense = DenseLayer(dense, num_units=num_units, nonlinearity=lasagne.nonlinearities.linear, name='output')\n",
    "    all_vectors_output = ReshapeLayer(output_dense, (-1, 3, num_units))\n",
    "\n",
    "    return all_vectors_output, output_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_triplets = T.tensor4(\"Triplets input\", dtype=\"float32\")\n",
    "target = T.ivector(\"Target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "triplets_input = InputLayer((None, 3) + SOUND_SHAPE, input_var=input_triplets)\n",
    "# people_inputs = InputLayer((None, 2, 500, 513))\n",
    "# from lasagne.layers import dimshuffle\n",
    "# dimshuffle(triplets_input,[0,1,3,2])\n",
    "vectorizer, _ = make_speechtovec(lasagne.layers.dimshuffle(triplets_input,[0,1,3,2]), SOUND_SHAPE[::-1], 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasagne.layers.set_all_param_values(vectorizer, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_pred = get_output(vectorizer)\n",
    "params = get_all_params(vectorizer, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_func(all_predicted):\n",
    "    def distance_sq(x1, x2):\n",
    "        return T.sum(T.sqr(x1 - x2))\n",
    "\n",
    "    d1 = distance_sq(all_predicted[:, 0], all_predicted[:, 1])\n",
    "    d2 = distance_sq(all_predicted[:, 0], all_predicted[:, 2])\n",
    "    alpha = 1e-2\n",
    "\n",
    "    return T.maximum(d1 + alpha, 0) - T.maximum(d2 + alpha, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_sim(vec1, vec2):\n",
    "    numerator = T.sum(vec1*vec2)\n",
    "    denumenator = T.sqrt(T.sum(vec1**2)*T.sum(vec2**2))\n",
    "    return numerator/denumenator\n",
    "\n",
    "def denum_fun(v1, v2, similar_v, epsilon=0.0001):\n",
    "    if similar_v:\n",
    "        return (cos_sim(v1, v2) + 1)/2 + epsilon\n",
    "    else:\n",
    "        return (cos_sim(v1, v2) - 1)/2 + epsilon\n",
    "\n",
    "def loss_func_new(all_predicted, epsilon=0.0001):\n",
    "    def distance_sq(x1, x2):\n",
    "        return T.sum(T.sqr(x1 - x2))\n",
    "\n",
    "    d1 = distance_sq(all_predicted[:, 0], all_predicted[:, 1])\n",
    "    d2 = distance_sq(all_predicted[:, 0], all_predicted[:, 2])\n",
    "    \n",
    "    d1 /= denum_fun(all_predicted[:, 0], all_predicted[:, 1], True)\n",
    "    d2 /= denum_fun(all_predicted[:, 0], all_predicted[:, 2], False)\n",
    "    alpha = 1e-2\n",
    "\n",
    "    return T.maximum(d1 + alpha, 0) - T.maximum(d2 + alpha, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = loss_func(all_pred)\n",
    "\n",
    "updates = adagrad(loss, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = theano.function([triplets_input.input_var], updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = None\n",
    "users = VoicesData(\"../../data/users.dl\")\n",
    "for i in range(5):\n",
    "    data = users.get_train_vec()\n",
    "    for t in data:\n",
    "        try:\n",
    "            t = np.array(t)\n",
    "\n",
    "            if t.shape[0] > 1000:\n",
    "                train(t[:500])\n",
    "                train(t[500:1000])\n",
    "                train(t[1000:])\n",
    "            elif t.shape[0] > 500:\n",
    "                train(t[:500])\n",
    "                train(t[500:])\n",
    "            else:\n",
    "                train(t)\n",
    "\n",
    "            shape = t.shape\n",
    "            del t\n",
    "        except MemoryError:\n",
    "            print(t.shape, shape)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(\"../../data/weights_vec_new_new.npy\", lasagne.layers.get_all_param_values(vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = np.load(\"../../data/weights_vec_new.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = np.load(\"../../data/tvorog_vectorizer.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr = theano.function([triplets_input.input_var], all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = None\n",
    "for t in data:\n",
    "    print(pr(t))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(t).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in get_all_layers(vectorizer):\n",
    "    print (l, l.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siminput = T.tensor3(\"Similar voice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "triplets_input = InputLayer((None, 2) + SOUND_SHAPE, input_var=input_triplets)\n",
    "# nn = lasagne.layers.batch_norm(triplets_input)\n",
    "# people_inputs = InputLayer((None, 2, 500, 513))\n",
    "# from lasagne.layers import dimshuffle\n",
    "_ ,vectorizer= make_speechtovec(lasagne.layers.dimshuffle(triplets_input,[0,1,3,2]), SOUND_SHAPE[::-1], 300)\n",
    "\n",
    "similar_inp = lasagne.layers.InputLayer((None, 2, 300), input_var=siminput)\n",
    "# vector_output = ReshapeLayer(vectorizer, (-1, 2, 300))\n",
    "nn = lasagne.layers.batch_norm(similar_inp)\n",
    "conv_layer = Conv1DLayer(nn, 100, 2)\n",
    "nn = lasagne.layers.batch_norm(conv_layer)\n",
    "dense0 = DenseLayer(nn, 150)\n",
    "nn = lasagne.layers.batch_norm(dense0)\n",
    "dense0 = DenseLayer(nn, 50)\n",
    "nn = lasagne.layers.batch_norm(dense0)\n",
    "output = DenseLayer(nn, 1, nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "# dense0 = DenseLayer(vector_output, 100)\n",
    "# nn = lasagne.layers.batch_norm(dense0)\n",
    "# output = DenseLayer(nn, 1, nonlinearity=lasagne.nonlinearities.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasagne.layers.set_all_param_values(vectorizer, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = lasagne.layers.get_output(output)\n",
    "vec_pr = lasagne.layers.get_output(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parametrs = lasagne.layers.get_all_params(output, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = lasagne.objectives.binary_crossentropy(predict, target).sum()\n",
    "acc = lasagne.objectives.binary_accuracy(predict, target).mean()\n",
    "updates = lasagne.updates.adamax(loss, parametrs,learning_rate = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = theano.function([similar_inp.input_var, target] ,updates=updates, allow_input_downcast=True)\n",
    "vectoriz = theano.function([triplets_input.input_var], vec_pr, allow_input_downcast=True)\n",
    "presd = theano.function([similar_inp.input_var],predict ,allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = np.arange(len(X))\n",
    "np.random.shuffle(ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_train, in_test = ind[1000:], ind[:1000]\n",
    "# y_train, y_test = Y[1000:], Y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, ind, batchsize, shuffle=True):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(ind))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in tqdm(range(0, len(ind) - batchsize + 1, batchsize)):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[ind[excerpt]], targets[ind[excerpt]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasagne.layers.set_all_param_values(output, np.load(\"../../data/weights/symvoice_weights.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    st = time()\n",
    "    for i, batch in enumerate(iterate_minibatches(X, y, in_train, 1000)):\n",
    "#         print(\"Hey\")\n",
    "        x_tr, y_tr = batch\n",
    "        train(vectoriz(x_tr).reshape((-1, 2, 300)), y_tr)\n",
    "#         print(\"Hop\")\n",
    "#         break\n",
    "        if i > 100:\n",
    "            break\n",
    "#     break\n",
    "    print('\\r', \"Time: \", (time()-st)/60.)\n",
    "    print(\"\\tAccuracy: \", roc_auc_score(y[in_test], presd(vectoriz(X[in_test]).reshape((-1, 2, 300)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train, vectoriz, presd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasagne.layers.get_all_param_values(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc_fun(X[in_test], y[in_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y[in_test].sum()/len(y[in_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y[in_test], presd(vectoriz(X[in_test]).reshape((-1, 2, 300))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"../../data/simvoice_weights.npy\", lasagne.layers.get_all_param_values(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"../../data/vectorizer_weights.npy\", lasagne.layers.get_all_param_values(vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectoriz(X[in_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "07020d92a8824c7daba0b5f9b30d24f7": {
     "views": [
      {
       "cell_index": 51
      }
     ]
    },
    "2a8260d8a0114bf695a68cb4f6827ba4": {
     "views": [
      {
       "cell_index": 52
      }
     ]
    },
    "2eede4da7d634f688d9acb790271af82": {
     "views": [
      {
       "cell_index": 52
      }
     ]
    },
    "43ae7cab29894b4f99c6113b9ce1fbbc": {
     "views": [
      {
       "cell_index": 52
      }
     ]
    },
    "4d84f47223d14e1793469e3648e1a16e": {
     "views": [
      {
       "cell_index": 52
      }
     ]
    },
    "4f43186ce5bb44bbb92bad5ed498c5b6": {
     "views": [
      {
       "cell_index": 52
      }
     ]
    },
    "561016b9bdc14d63ade96c1c66b8cfde": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "65ef4ca340fb4772a44949acc45a6d06": {
     "views": [
      {
       "cell_index": 52
      }
     ]
    },
    "70b95355eba7420fb2198b63960b141a": {
     "views": [
      {
       "cell_index": 51
      }
     ]
    },
    "86aa6686fb5645c8a73bd422cb42f091": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "8f13433ad80a4842bc5a1fce6109544d": {
     "views": [
      {
       "cell_index": 52
      }
     ]
    },
    "92f1a3d9d8fe477d805542b3d9fa0c5b": {
     "views": [
      {
       "cell_index": 51
      }
     ]
    },
    "9c0d59b820dc498c898a0af924878109": {
     "views": [
      {
       "cell_index": 51
      }
     ]
    },
    "cc3311eac8fb465887ba6823a201609d": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "d12a94b393fa4c13981f901725c5bbd1": {
     "views": [
      {
       "cell_index": 52
      }
     ]
    },
    "e27d9c6e6c75421aa7d82131e29c0f48": {
     "views": [
      {
       "cell_index": 52
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
