{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Для того, чтобы получить чиселки из изображения\n",
    "import numpy as np\n",
    "\n",
    "# Для того, чтобы получить изображение\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(img_name):\n",
    "    '''Функция, которая возращает спектограмму по id'''\n",
    "    return np.array(Image.open(\"../../data/images/{}.png\".format(img_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Для загрузки и обработки csv с данными\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузим данные\n",
    "data = pd.DataFrame.from_csv(\"../../data/pronuns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronun_rank</th>\n",
       "      <th>_id</th>\n",
       "      <th>visits</th>\n",
       "      <th>gender</th>\n",
       "      <th>word_rank</th>\n",
       "      <th>user</th>\n",
       "      <th>accent</th>\n",
       "      <th>votes</th>\n",
       "      <th>pronun_id</th>\n",
       "      <th>pronuns</th>\n",
       "      <th>best_pronuns</th>\n",
       "      <th>word</th>\n",
       "      <th>when_word_added</th>\n",
       "      <th>global_listenings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>662</td>\n",
       "      <td>585fc620698f824ee334a626</td>\n",
       "      <td>61503</td>\n",
       "      <td>False</td>\n",
       "      <td>1564</td>\n",
       "      <td>mariad</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>585fda10698f828c848d862d</td>\n",
       "      <td>573</td>\n",
       "      <td>199</td>\n",
       "      <td>0_zero</td>\n",
       "      <td>2010-04-25</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21737</td>\n",
       "      <td>585fc7f4698f824ee334afc3</td>\n",
       "      <td>303426</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>Wojtula</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>585fda11698f828c848d862e</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11_jedenaście</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>585fc5e7698f824ee334a4ea</td>\n",
       "      <td>162426</td>\n",
       "      <td>False</td>\n",
       "      <td>998</td>\n",
       "      <td>usako_usagiclub</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "      <td>585fda11698f828c848d862f</td>\n",
       "      <td>25504</td>\n",
       "      <td>0</td>\n",
       "      <td>１１９番</td>\n",
       "      <td>2015-06-06</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>228</td>\n",
       "      <td>585fc8e7698f824ee334b4d5</td>\n",
       "      <td>60338</td>\n",
       "      <td>True</td>\n",
       "      <td>13400</td>\n",
       "      <td>SeanMauch</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>585fda11698f828c848d8630</td>\n",
       "      <td>1765</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008-07-10</td>\n",
       "      <td>57K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>585fc854698f824ee334b1ca</td>\n",
       "      <td>342195</td>\n",
       "      <td>False</td>\n",
       "      <td>641</td>\n",
       "      <td>anakat</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>585fda11698f828c848d8631</td>\n",
       "      <td>2851</td>\n",
       "      <td>969</td>\n",
       "      <td>12</td>\n",
       "      <td>2008-07-10</td>\n",
       "      <td>57K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pronun_rank                       _id  visits gender  word_rank  \\\n",
       "0          662  585fc620698f824ee334a626   61503  False       1564   \n",
       "1        21737  585fc7f4698f824ee334afc3  303426   True         14   \n",
       "2            9  585fc5e7698f824ee334a4ea  162426  False        998   \n",
       "3          228  585fc8e7698f824ee334b4d5   60338   True      13400   \n",
       "4          153  585fc854698f824ee334b1ca  342195  False        641   \n",
       "\n",
       "              user         accent  votes                 pronun_id  pronuns  \\\n",
       "0           mariad          Spain      0  585fda10698f828c848d862d      573   \n",
       "1          Wojtula  United States      0  585fda11698f828c848d862e        7   \n",
       "2  usako_usagiclub          Japan      1  585fda11698f828c848d862f    25504   \n",
       "3        SeanMauch  United States      0  585fda11698f828c848d8630     1765   \n",
       "4           anakat  United States      0  585fda11698f828c848d8631     2851   \n",
       "\n",
       "   best_pronuns           word when_word_added global_listenings  \n",
       "0           199         0_zero      2010-04-25               192  \n",
       "1             0  11_jedenaście      2013-05-18               638  \n",
       "2             0           １１９番      2015-06-06               743  \n",
       "3             0             12      2008-07-10               57K  \n",
       "4           969             12      2008-07-10               57K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузим данные в 'классном' виде\n",
    "from collections import defaultdict\n",
    "\n",
    "users_pronun_dict = defaultdict(lambda: list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Статус бар\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm_notebook(data.values):\n",
    "    users_pronun_dict[row[5]].append(row[8]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ones = []\n",
    "parity = []\n",
    "\n",
    "for user in tqdm_notebook(users_pronun_dict.keys()):\n",
    "    user_items = users_pronun_dict[user]\n",
    "    \n",
    "    if len(user_items) == 1:\n",
    "        ones.append((user, user_items))\n",
    "    elif len(user_items) % 2 == 0:\n",
    "        for item_index in range(0, len(user_items), 2):\n",
    "            parity.append((user, [user_items[item_index-1], user_items[item_index]]))\n",
    "    \n",
    "    else:\n",
    "        ones.append((user, [user_items[0]]))\n",
    "        \n",
    "        user_items = user_items[1:]\n",
    "        for item_index in range(0, len(user_items), 2):\n",
    "            parity.append((user, [user_items[item_index-1], user_items[item_index]]))\n",
    "\n",
    "for tpl in parity:\n",
    "    if len(ones) + 2 < len(parity):\n",
    "        ones.append((tpl[0], [tpl[1][0]]))\n",
    "        ones.append((tpl[0], [tpl[1][1]]))\n",
    "\n",
    "parity = parity[len(parity) - len(ones):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for a, b in zip(parity, ones):\n",
    "    dataset.append(a[1] + b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOUND_SHAPE = (500, 513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def as_matrix(ar, shape = (500, 513)):\n",
    "    ret_mat = np.zeros((len(ar), shape[0], shape[1]), dtype=\"float16\")\n",
    "    for i, vec in enumerate(ar):\n",
    "        try:\n",
    "            if vec.shape[0] > shape[0]:\n",
    "                ret_mat[i, :, :] = vec[:shape[0], :]/200.\n",
    "            else:\n",
    "                ret_mat[i, :vec.shape[0], :] = vec/200.\n",
    "        except IndexError:\n",
    "            print(vec.shape)\n",
    "            raise IndexError\n",
    "\n",
    "    return ret_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    global dataset\n",
    "    shuffle(dataset)\n",
    "    \n",
    "    train = []\n",
    "    for i in dataset:\n",
    "        m1, m2, m3 = get_spectrogram(i[0]), get_spectrogram(i[1]), get_spectrogram(i[2])\n",
    "        if len(train) == 100:\n",
    "            yield train\n",
    "            train = []\n",
    "        else:\n",
    "            train.append(as_matrix((m1, m2, m3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"device=gpu1\"\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=\"device=gpu1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 1: GeForce GTX 1080 (CNMeM is enabled with initial size: 45.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "from lasagne.layers import InputLayer, DenseLayer, ReshapeLayer, Conv1DLayer, MaxPool1DLayer, GlobalPoolLayer, \\\n",
    "    get_output, get_all_params, get_all_param_values, set_all_param_values\n",
    "\n",
    "from lasagne.nonlinearities import very_leaky_rectify, tanh\n",
    "\n",
    "from lasagne.updates import adagrad\n",
    "\n",
    "def make_speechtovec(incoming, sound_shape, num_units, **kwargs):\n",
    "    \"\"\"\n",
    "    :param incoming: the layer feeding into this layer, or the expected input shape.\n",
    "    :param sound_shape: shape of freq x time\n",
    "    :param num_units: output vector dimension\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    input_reshape = ReshapeLayer(incoming, (-1,) + sound_shape)  # Сворачиваем все записи друг за другом\n",
    "    convolution = Conv1DLayer(input_reshape, num_filters=100, filter_size=5,\n",
    "                              nonlinearity=very_leaky_rectify, name=\"Convolutional\")\n",
    "    pooling = MaxPool1DLayer(convolution, 2)\n",
    "    global_pooling = GlobalPoolLayer(pooling)\n",
    "    dense = DenseLayer(global_pooling, num_units=300, name=\"Dense\")\n",
    "    output_dense = DenseLayer(dense, num_units=num_units, nonlinearity=lasagne.nonlinearities.linear, name='output')\n",
    "    all_vectors_output = ReshapeLayer(output_dense, (-1, 3, num_units))\n",
    "\n",
    "    return all_vectors_output, output_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_triplets = T.tensor4(\"Triplets input\", dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "triplets_input = InputLayer((None, 3) + SOUND_SHAPE, input_var=input_triplets)\n",
    "# people_inputs = InputLayer((None, 2, 500, 513))\n",
    "# from lasagne.layers import dimshuffle\n",
    "# dimshuffle(triplets_input,[0,1,3,2])\n",
    "vectorizer, _ = make_speechtovec(lasagne.layers.dimshuffle(triplets_input,[0,1,3,2]), SOUND_SHAPE[::-1], 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_pred = get_output(vectorizer)\n",
    "params = get_all_params(vectorizer, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_func(all_predicted):\n",
    "    def distance_sq(x1, x2):\n",
    "        return T.sum(T.sqr(x1 - x2))\n",
    "\n",
    "    d1 = distance_sq(all_predicted[:, 0], all_predicted[:, 1])\n",
    "    d2 = distance_sq(all_predicted[:, 0], all_predicted[:, 2])\n",
    "    alpha = 1e-2\n",
    "\n",
    "    return T.maximum(d1 + alpha, 0) - T.maximum(d2 + alpha, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_sim(vec1, vec2):\n",
    "    numerator = T.sum(vec1*vec2)\n",
    "    denumenator = T.sqrt(T.sum(vec1**2)*T.sum(vec2**2))\n",
    "    return numerator/denumenator\n",
    "\n",
    "def denum_fun(v1, v2, similar_v, epsilon=0.0001):\n",
    "    if similar_v:\n",
    "        return (cos_sim(v1, v2) + 1)/2 + epsilon\n",
    "    else:\n",
    "        return (cos_sim(v1, v2) - 1)/2 + epsilon\n",
    "\n",
    "def loss_func_new(all_predicted, epsilon=0.0001):\n",
    "    def distance_sq(x1, x2):\n",
    "        return T.sum(T.sqr(x1 - x2))\n",
    "\n",
    "    d1 = distance_sq(all_predicted[:, 0], all_predicted[:, 1])\n",
    "    d2 = distance_sq(all_predicted[:, 0], all_predicted[:, 2])\n",
    "    \n",
    "    d1 /= denum_fun(all_predicted[:, 0], all_predicted[:, 1], True)\n",
    "    d2 /= denum_fun(all_predicted[:, 0], all_predicted[:, 2], False)\n",
    "    alpha = 1e-2\n",
    "\n",
    "    return T.maximum(d1 + alpha, 0) - T.maximum(d2 + alpha, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = loss_func_new(all_pred)\n",
    "\n",
    "updates = lasagne.updates.adamax(loss, params,learning_rate = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = theano.function([triplets_input.input_var], updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(100000):\n",
    "    for t in tqdm_notebook(get_dataset()):\n",
    "        try:\n",
    "            t = np.array(t)\n",
    "\n",
    "            if t.shape[0] > 700:\n",
    "                train(t[:700])\n",
    "                train(t[700:])\n",
    "            else:\n",
    "                train(t)\n",
    "\n",
    "            shape = t.shape\n",
    "            del t\n",
    "        except MemoryError:\n",
    "            print(t.shape, shape)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(open('../../data/tvorog_vectorizer.npy', 'wb'), lasagne.layers.get_all_param_values(layer=vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "043f2cc6eec44cd4bf7cef30b6342b6a": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "1414ceaf1d1c4721bfbb5f5848447707": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "19e92667e75942c1ae6f8cb0b88d15df": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "1f57e8592a374d7f98888e76bf6e7222": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "2b61717825644c68ab0301190d616d74": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "31e3de50c6654b499f54388af14e5425": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "371f41e49f2a4d3b8d55d638909f1263": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "3b496970d1294d4f8355bc98e7e6b0d3": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "40a137f612f743f2bf16429549c274c9": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "4bea74ecf73b456eae712411faf04f42": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "55a14c5464a34f3c942e5a54aedf4cc8": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "89e77bb712ae4c94b0a60067f32ccbf3": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "8db32950f61141bcade07e817158aaeb": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "a9a9de83937343a38420f5038fc775f2": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "d1284237e2a345669d49106f3be1507b": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "d4c40b7103224bdb9fe2f9379f2ea050": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "d82f55b6b02d4bf4ae1bf05b48d56f4a": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "f021628f3cd94cca81b55b187906db3d": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "f4520fa8e0e5457787ff01150e9a387b": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "f9ce8e6547f84179a6e1f9a887d4c96d": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
