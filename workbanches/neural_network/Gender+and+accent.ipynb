{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"device=gpu4\"\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=\"device=gpu4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from librosa import load, logamplitude\n",
    "from librosa.feature import melspectrogram\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../clear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from CoolSoundNetwork import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv(\"../../data/pronuns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronun_rank</th>\n",
       "      <th>_id</th>\n",
       "      <th>visits</th>\n",
       "      <th>gender</th>\n",
       "      <th>word_rank</th>\n",
       "      <th>user</th>\n",
       "      <th>accent</th>\n",
       "      <th>votes</th>\n",
       "      <th>pronun_id</th>\n",
       "      <th>pronuns</th>\n",
       "      <th>best_pronuns</th>\n",
       "      <th>word</th>\n",
       "      <th>when_word_added</th>\n",
       "      <th>global_listenings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>662</td>\n",
       "      <td>585fc620698f824ee334a626</td>\n",
       "      <td>61503</td>\n",
       "      <td>False</td>\n",
       "      <td>1564</td>\n",
       "      <td>mariad</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>585fda10698f828c848d862d</td>\n",
       "      <td>573</td>\n",
       "      <td>199</td>\n",
       "      <td>0_zero</td>\n",
       "      <td>2010-04-25</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21737</td>\n",
       "      <td>585fc7f4698f824ee334afc3</td>\n",
       "      <td>303426</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>Wojtula</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>585fda11698f828c848d862e</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11_jedenaście</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>585fc5e7698f824ee334a4ea</td>\n",
       "      <td>162426</td>\n",
       "      <td>False</td>\n",
       "      <td>998</td>\n",
       "      <td>usako_usagiclub</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "      <td>585fda11698f828c848d862f</td>\n",
       "      <td>25504</td>\n",
       "      <td>0</td>\n",
       "      <td>１１９番</td>\n",
       "      <td>2015-06-06</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>228</td>\n",
       "      <td>585fc8e7698f824ee334b4d5</td>\n",
       "      <td>60338</td>\n",
       "      <td>True</td>\n",
       "      <td>13400</td>\n",
       "      <td>SeanMauch</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>585fda11698f828c848d8630</td>\n",
       "      <td>1765</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008-07-10</td>\n",
       "      <td>57K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>585fc854698f824ee334b1ca</td>\n",
       "      <td>342195</td>\n",
       "      <td>False</td>\n",
       "      <td>641</td>\n",
       "      <td>anakat</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>585fda11698f828c848d8631</td>\n",
       "      <td>2851</td>\n",
       "      <td>969</td>\n",
       "      <td>12</td>\n",
       "      <td>2008-07-10</td>\n",
       "      <td>57K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pronun_rank                       _id  visits gender  word_rank  \\\n",
       "0          662  585fc620698f824ee334a626   61503  False       1564   \n",
       "1        21737  585fc7f4698f824ee334afc3  303426   True         14   \n",
       "2            9  585fc5e7698f824ee334a4ea  162426  False        998   \n",
       "3          228  585fc8e7698f824ee334b4d5   60338   True      13400   \n",
       "4          153  585fc854698f824ee334b1ca  342195  False        641   \n",
       "\n",
       "              user         accent  votes                 pronun_id  pronuns  \\\n",
       "0           mariad          Spain      0  585fda10698f828c848d862d      573   \n",
       "1          Wojtula  United States      0  585fda11698f828c848d862e        7   \n",
       "2  usako_usagiclub          Japan      1  585fda11698f828c848d862f    25504   \n",
       "3        SeanMauch  United States      0  585fda11698f828c848d8630     1765   \n",
       "4           anakat  United States      0  585fda11698f828c848d8631     2851   \n",
       "\n",
       "   best_pronuns           word when_word_added global_listenings  \n",
       "0           199         0_zero      2010-04-25               192  \n",
       "1             0  11_jedenaście      2013-05-18               638  \n",
       "2             0           １１９番      2015-06-06               743  \n",
       "3             0             12      2008-07-10               57K  \n",
       "4           969             12      2008-07-10               57K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accent_count = len(df.accent.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.sandbox.cuda): ERROR: Not using GPU. Initialisation of device 4 failed:\n",
      "initCnmem: cnmemInit call failed! Reason=CNMEM_STATUS_OUT_OF_MEMORY. numdev=1\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is enabled with initial size: 45.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_tensor = T.matrix(\"Vector input\")\n",
    "target_gender = T.ivector(\"Target gender\")\n",
    "target_accent = T.ivector(\"Target acent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_ = lasagne.layers.InputLayer((100, 100), input_var=input_tensor, name=\"Network input\")\n",
    "batch_norm0 = lasagne.layers.batch_norm(input_, name=\"Batch normalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense0 = lasagne.layers.DenseLayer(batch_norm0, 50, name=\"Dense 0\")\n",
    "dense1 = lasagne.layers.DenseLayer(dense0, 20, name=\"Dense 1\")\n",
    "gender_out = lasagne.layers.DenseLayer(dense1, 1, nonlinearity=lasagne.nonlinearities.sigmoid, name=\"Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_out.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_predicted = lasagne.layers.get_output(gender_out)\n",
    "gender_param = lasagne.layers.get_all_params(gender_out, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_loss = lasagne.objectives.binary_crossentropy(gender_predicted, target_gender).mean()\n",
    "\n",
    "gender_updates = lasagne.updates.adagrad(gender_loss, gender_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense0 = lasagne.layers.DenseLayer(batch_norm0, 200, name=\"Dense 0\")\n",
    "accent_out = lasagne.layers.DenseLayer(dense0, accent_count,\n",
    "                                       nonlinearity=lasagne.nonlinearities.softmax, name=\"Accent output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 111)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accent_out.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accent_predicted = lasagne.layers.get_output(accent_out)\n",
    "accent_param = lasagne.layers.get_all_params(accent_out, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accent_loss = lasagne.objectives.binary_crossentropy(accent_predicted, target_accent).mean()\n",
    "\n",
    "accent_updates = lasagne.updates.adagrad(accent_loss, accent_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_train = theano.function([input_.input_var, target_gender], updates=gender_updates)\n",
    "accent_train = theano.function([input_.input_var, target_accent], updates=accent_updates)\n",
    "\n",
    "gender_predict = theano.function([input_.input_var], gender_predicted)\n",
    "accent_predict = theano.function([input_.input_var], accent_predicted)\n",
    "\n",
    "predict = theano.function([input_.input_var], [gender_predicted, accent_predicted])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = Network(load_weights=False, vec_weights_file_name='../../data/weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../data/images/\"\n",
    "output_path = \"../../data/vectors/\"\n",
    "for im in tqdm(os.listdir(\"../../data/images/\")):\n",
    "    img = Image.open(data_path+im)\n",
    "    vectors = network.vectorizer(voice_array=np.array(img))\n",
    "    for index, vector in enumerate(vectors):\n",
    "        np.save(output_path+im.strip(\".png\")+\"_\"+str(index), vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter dataset\n",
    "count = 0\n",
    "recordings = pd.Series(index=df.pronun_id.unique())\n",
    "for file in tqdm(os.listdir(\"../../data/vectors/\")):\n",
    "    name = file.split(\"_\")[0]\n",
    "    try:\n",
    "        recordings[name]\n",
    "    except:\n",
    "        os.remove(\"../../data/vectors/\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make test\n",
    "test = df[df.pronun_id.isin(list(map(lambda x: x.split(\"_\")[0], os.listdir(\"../../data/vectors/test/\"))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = df[~df.pronun_id.isin(test.pronun_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "women = t[t.gender == False].pronun_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    673\n",
       "True     626\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "counter = 0\n",
    "dire = os.listdir(\"../../data/vectors/\")\n",
    "for f in dire:\n",
    "    if f.split(\"_\")[0] in women.values:\n",
    "        shutil.move(\"../../data/vectors/\"+f, \"../../data/vectors/test/\"+f)\n",
    "        counter += 1\n",
    "        if counter == 200:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now i sware we are training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(input_path, df, batchsize, index_col=\"pronun_id\", target_names=[\"gender\"],shuffle=True):\n",
    "    input_files = np.array(list(map(lambda x: input_path+x, os.listdir(input_path))))\n",
    "    df = df.set_index(index_col)\n",
    "    targets = df[target_names]\n",
    "    del df\n",
    "    if shuffle:\n",
    "        indices = np.arange(input_files.size)\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(input_files) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        inputs = []\n",
    "        recordings = []\n",
    "        rec_targ = []\n",
    "        for inp in input_files[excerpt]:\n",
    "            naming = inp.split(\"_\")[0].split(\"/\")\n",
    "            name = naming[len(naming)-1]\n",
    "            inputs.append(np.load(inp))\n",
    "            rec_targ.append(targets[name])\n",
    "        yield np.array(inputs), np.array(rec_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "13350\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-36d6e5f1b0ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/vectors/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mgender_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcurr\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-146-d78d2473fef8>\u001b[0m in \u001b[0;36miterate_minibatches\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mnaming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaming\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mrec_targ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_targ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0m_ZIP_PREFIX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PK\\x03\\x04'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIC_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# back-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ZIP_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH = 5\n",
    "size = df.pronun_id.size\n",
    "curr = 0\n",
    "for epoch in range(EPOCH):\n",
    "    for x, y in iterate_minibatches(\"../../data/vectors/\", df, 150):\n",
    "        gender_train(x, y)\n",
    "        curr+= 150\n",
    "        clear_output()\n",
    "        print(\"Epoch: \", epoch)\n",
    "        print(\"Accuracy: \", gender_loss())\n",
    "        print(curr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
