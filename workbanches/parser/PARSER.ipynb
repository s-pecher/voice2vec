{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import concurrent\n",
    "import numpy as np\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_word(word):\n",
    "    html = urlopen(\"https://forvo.com/word/\" + urllib.parse.quote(word.encode(\"utf-8\"))).read().decode()\n",
    "\n",
    "    root = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    answer = {}\n",
    "    answer[\"word\"] = word\n",
    "    categories = []\n",
    "\n",
    "    for a in root.find(\"div\", {\"class\": \"categories\"}).findAll(\"a\"):\n",
    "        categories.append((a.text, a[\"href\"]))\n",
    "\n",
    "    answer[\"metadata\"] = {\n",
    "        \"added\": root.find(\"div\", {\"class\": \"metadata\"}).text.split(\"\\n\")[1].split(\" \")[-1], \n",
    "                          \"num_listenings\": root.find(\"div\", {\"class\": \"metadata\"}).find(\"span\").text\n",
    "    }\n",
    "    try:\n",
    "        answer[\"langs\"] = [i.text for i in root.find(\"nav\", {\"class\": \"nav_langs\"}).findAll(\"li\")]\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    pronounce = []\n",
    "\n",
    "    for article in root.findAll(\"article\"):\n",
    "        for li in article.findAll(\"li\"):\n",
    "            tmp = {}\n",
    "            try:\n",
    "                tmp[\"author\"] = li.find(\"a\", {\"class\": \"uLink\"}).text\n",
    "                tmp[\"votes\"] = li.find(\"span\", {\"class\": \"num_votes\"}).text\n",
    "                tmp[\"href\"] = li.find(\"p\", {\"class\": \"download\"}).find(\"a\")[\"href\"]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            pronounce.append(tmp)\n",
    "\n",
    "    answer[\"pronounces\"] = pronounce\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags = []\n",
    "\n",
    "for i in tqdm(range(6429)):\n",
    "    url = \"https://forvo.com/tags/all/by-popularity/page-{0}/\".format(i)\n",
    "    html = urlopen(url).read().decode()\n",
    "\n",
    "    root = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    for li in root.find(\"section\", {\"class\": \"main_section\"}).findAll(\"li\"):\n",
    "        a = li.find(\"a\")\n",
    "        try:\n",
    "            if \"/tag/\" in a[\"href\"]:\n",
    "                tags.append((a[\"href\"], a.text))\n",
    "        except TypeError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pickle.dump(tags, open(\"tags.pck\",\"wb\"))\n",
    "tags = pickle.load(open(\"tags.pck\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_htmls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_ans(das):\n",
    "    url = das + \"alphabetically/\"\n",
    "    html = urlopen(url).read().decode()\n",
    "    root = BeautifulSoup(html, \"html.parser\")\n",
    "    all_aph = []\n",
    "    for li in root.find(\"nav\", {\"class\": \"alphabet\"}).findAll(\"li\"):\n",
    "        all_aph.append(url[:-24] + li.find(\"a\")['href'])\n",
    "\n",
    "    def get_words(root):\n",
    "        for li in root.findAll(\"ul\")[-4].findAll(\"li\"):\n",
    "            try:\n",
    "                word = li.find(\"a\").text\n",
    "            except AttributeError:\n",
    "                return\n",
    "            word = word.replace(\" pronunciation\", \"\").replace(\" \",\"_\")\n",
    "            try:\n",
    "                tmp_client = MongoClient()\n",
    "                tmp_db = tmp_client.voice\n",
    "                tmp_db.word.insert_one(parse_word(word))\n",
    "            except urllib.error.HTTPError:\n",
    "                pass\n",
    "        \n",
    "        if root.find(\"a\", {\"rel\": \"next\"}) != None:\n",
    "            get_words(BeautifulSoup(urlopen(root.find(\"a\", {\"rel\": \"next\"})[\"href\"]).read().decode(), \"html.parser\"))\n",
    "    \n",
    "    for url in tqdm(all_aph):\n",
    "        get_words(BeautifulSoup(urlopen(url).read().decode(), \"html.parser\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/192868 [00:00<?, ?it/s]\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|â–Ž         | 1/28 [00:00<00:03,  7.52it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "for i in tqdm([i[0] for i in tags][2:]):\n",
    "    get_ans(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
